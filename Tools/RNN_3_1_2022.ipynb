{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe8df9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helper import softmax, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1a9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_forward(x_t, a_prev_t, parameters):\n",
    "    \"\"\"\n",
    "    This implements the rnn block of the rnn-network for forward propagation.\n",
    "    Suitable for many-to-many architecture (Tx=Ty).\n",
    "    Arguments:\n",
    "        x_t:Input data for the current timestep, having dimensions (n_x, m)\n",
    "        a_prev_t: Hidden state for the previous time-step , having dimensions of (n_a, m)\n",
    "        Parameters is a dictionary of parameters: Waa, Wax, Wya, by, ba\n",
    "    \n",
    "    Returns:\n",
    "        a_next_t:Hidden state for the current timestep , having dimensions of (n_a, m)\n",
    "        y_pred_t: Prediction for the current time-step , having dimensions (n_y, m)\n",
    "    \n",
    "    \"\"\"\n",
    "    Wax=parameters[\"Wax\"]\n",
    "    Waa=parameters[\"Waa\"]\n",
    "    Wya=parameters[\"Wya\"]\n",
    "    by=parameters[\"by\"]\n",
    "    ba=parameters[\"ba\"]\n",
    "    \n",
    "    a_next_t=np.tanh(np.dot(Wax, x_t)+np.dot(Waa, a_prev_t)+ba)\n",
    "    y_pred_t=softmax(np.dot(Wya, a_next_t)+by)\n",
    "    return (a_next_t, y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward_pass(x,a0, parameters):\n",
    "    \"\"\"\n",
    "    This implements the forward pass of the rnn network with RNN block.\n",
    "    Arguments:\n",
    "        x: Input data, having dimensions of (n_x, m, T_x)\n",
    "        a0:Initial hidden state , having dimensions of (n_a, m)\n",
    "        Parameters is a dictionary of parameters: Waa, Wax, Wya, by, ba\n",
    "        \n",
    "    Returns :\n",
    "        a:Hidden state for all the time-steps, having dimensions of (n_a, m, T_x)\n",
    "        y_pred: Predictions for all the time-steps, having dimensions of (n_y, m, T_y) . Here, T_x=T_y\n",
    "    \n",
    "    \"\"\"\n",
    "    Wya=parameters[\"Wya\"]\n",
    "    \n",
    "    n_x, m, T_x=x.shape\n",
    "    n_y, n_a=Wya.shape\n",
    "    \n",
    "    a=np.zeros((n_a, m, T_x))\n",
    "    y_pred=np.zeros((n_y, m, T_x))\n",
    "    a_next=a0\n",
    "    \n",
    "    for i in range(T_x):\n",
    "        a[:,:,i],y_pred[:,:,i]=rnn_cell_forward(x[:,:,i], a_next, parameters)\n",
    "        a_next=a[:,:,i]\n",
    "    return (a, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29894ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell_forward(x_t, a_prev_t, c_prev_t, parameters):\n",
    "    \"\"\"\n",
    "    This implements the LSTM block of the rnn-network for forward propagation.\n",
    "    Arguments:\n",
    "        x_t: Input data for the current time-step, having dimensions of (n_x, m)\n",
    "        a_prev_t: Hidden state for the previous time-step, having dimensions of (n_a, m)\n",
    "        c_prev_t: Cell state for the previous time-step, having dimensions of (n_a, m)\n",
    "        Parameters is a dictionary of parameters: Wy, Wc, Wu, Wf, Wo, by, bc, bu, bf, bo\n",
    "    \n",
    "    Returns:\n",
    "        a_next_t: Hidden state for the current time-step, having dimensions of (n_a, m)\n",
    "        c_next_t: Cell state for the current time-step, having dimensions of (n_a, m)\n",
    "        y_pred_t: Prediction for thr current time-step, having dimensions of (n_y, m)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    Wy=parameters[\"Wy\"]\n",
    "    by=parameters[\"by\"]\n",
    "    \n",
    "    Wc=parameters[\"Wc\"]\n",
    "    bc=parameters[\"bc\"]\n",
    "    \n",
    "    Wu=parameters[\"Wu\"]\n",
    "    bu=parameters[\"bu\"]\n",
    "    \n",
    "    Wf=parameters[\"Wf\"]\n",
    "    bf=parameters[\"bf\"]\n",
    "    \n",
    "    Wo=parameters[\"Wo\"]\n",
    "    bo=parameters[\"bo\"]\n",
    "    \n",
    "    concat=np.concatenate((a_prev_t, x_t), axis=0)\n",
    "    \n",
    "    c_tilda_t=np.tanh(np.dot(Wc, concat)+bc)\n",
    "    ug=sigmoid(np.dot(Wu, concat)+bu)\n",
    "    fg=sigmoid(np.dot(Wf, concat)+bf)\n",
    "    og=sigmoid(np.dot(Wo, concat)+bo)\n",
    "    \n",
    "    c_next_t=ug*c_tilda_t+fg*c_prev_t\n",
    "    a_next_t=og*(np.tanh(c_next_t))\n",
    "    y_pred_t=softmax(np.dot(Wy, a_next_t)+by)\n",
    "    \n",
    "    return (a_next_t,c_next_t, y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_forward_pass(x, a0, parameters):\n",
    "    \"\"\"\n",
    "    This implements the forward pass of rnn-network with LSTM block.\n",
    "    Arguments:\n",
    "        x: Input data, having dimensions of (n_x, m, T_x)\n",
    "        a0:Initial hidden state , having dimensions of (n_a, m)\n",
    "        Parameters is a dictionary of parameters: Wy, Wc, Wu, Wf, Wo, by, bc, bu, bf, bo\n",
    "    \n",
    "    Returns:\n",
    "        a:Hidden state for all the time-steps, having dimensions of (n_a, m, T_x)\n",
    "        y_pred: Predictions for all the time-steps, having dimensions of (n_y, m, T_y) . Here, T_x=T_y\n",
    "        c:Cell state for all the time-steps, having dimensions of (n_a,m, T_x)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    n_x, m, T_x=x.shape\n",
    "    ny, na=parameters[\"Wy\"].shape\n",
    "    \n",
    "    a_next_t=a0\n",
    "    c_next_t=np.zeros((na, m))\n",
    "    a=np.zeros((na, m, T_x))\n",
    "    c=np.zeros((na, m, T_x))\n",
    "    y_pred=np.zeros((ny, m, T_x))\n",
    "    \n",
    "    for i in range(T_x):\n",
    "        a[:,:,i], c[:, :, i], y_pred[:,:,i]=lstm_cell_forward(x[:,:,i], a_next_t, c_next_t, parameters)\n",
    "        a_next_t=a[:,:,i]\n",
    "        c_next_t=c[:,:,i]\n",
    "    return (a,y_pred,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0394198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_cell_forward(x_t, a_prev_t, parameters):\n",
    "    \"\"\"\n",
    "    This implements the GRU block of the rnn-network for forward propagation.\n",
    "    Arguments:\n",
    "        x_t: Input data for the current time-step, having dimensions of (n_x, m)\n",
    "        a_prev_t: Hidden state for the previous time-step, having dimensions of (n_a, m)\n",
    "        Parameters is a dictionary of parameters: Wy, Wc, Wu, Wr, by, bc, bu, br\n",
    "    \n",
    "    Returns:\n",
    "        a_next_t: Hidden state for the current time-step, having dimensions of (n_a, m)\n",
    "        y_pred_t: Prediction for thr current time-step, having dimensions of (n_y, m)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Wu=parameters[\"Wu\"]\n",
    "    bu=parameters[\"bu\"]\n",
    "    \n",
    "    Wr=parameters[\"Wr\"]\n",
    "    br=parameters[\"br\"]\n",
    "        \n",
    "    Wc=parameters[\"Wc\"]\n",
    "    bc=parameters[\"bc\"]\n",
    "    \n",
    "    Wy=parameters[\"Wy\"]\n",
    "    by=parameters[\"by\"]\n",
    "    \n",
    "    concat=np.concatenate((a_prev_t, x_t), axis=0)\n",
    "    \n",
    "    update_gate=sigmoid(np.dot(Wu, concat)+bu)\n",
    "    relevance_gate=sigmoid(np.dot(Wr, concat)+br)\n",
    "    \n",
    "    concat_for_c_tilda=np.concatenate((update_gate*a_prev_t, x_t), axis=0)\n",
    "    \n",
    "    c_tilda_t=np.tanh(np.dot(Wc, concat_for_c_tilda)+bc)\n",
    "    a_next_t=update_gate*c_tilda_t+(1-update_gate)*a_prev_t\n",
    "    y_pred_t=softmax(np.dot(Wy, a_next_t)+by)\n",
    "    \n",
    "    return (a_next_t, y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bde9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_forward_pass(x, a0, parameters):\n",
    "    \"\"\"\n",
    "    This implements the forward pass of rnn-network with GRU block.\n",
    "    Arguments:\n",
    "        x: Input data, having dimensions of (n_x, m, T_x)\n",
    "        a0:Initial hidden state , having dimensions of (n_a, m)\n",
    "        Parameters is a dictionary of parameters: Wy, Wc, Wu, Wr, by, bc, bu, br\n",
    "    \n",
    "    Returns:\n",
    "        a:Hidden state for all the time-steps, having dimensions of (n_a, m, T_x)\n",
    "        y_pred: Predictions for all the time-steps, having dimensions of (n_y, m, T_y) . Here, T_x=T_y\n",
    "\n",
    "    \"\"\"\n",
    "    nx, m, T_x=x.shape\n",
    "    a_next=a0\n",
    "    n_y, n_a=parameters[\"Wy\"].shape\n",
    "    a=np.zeros((n_a, m, T_x))\n",
    "    y_pred=np.zeros((n_y, m, T_x))\n",
    "    for i in range(T_x):\n",
    "        a[:,:,i], y_pred[:,:,i]=gru_cell_forward(x[:,:,i], a_next, parameters)\n",
    "        a_next=a[:,:,i]\n",
    "    return (a, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (mission)",
   "language": "python",
   "name": "mission"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
